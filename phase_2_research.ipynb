{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from test_dataset import generate_synthetic_data\n",
    "from pcalg import estimate_cpdag\n",
    "from pcalg import estimate_skeleton\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import time\n",
    "from __future__ import print_function\n",
    "from itertools import combinations, permutations\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph generator based on the PC algorithm [Kalisch2007].\n",
    "\n",
    "[Kalisch2007] Markus Kalisch and Peter Bhlmann. Estimating\n",
    "high-dimensional directed acyclic graphs with the pc-algorithm. In The\n",
    "Journal of Machine Learning Research, Vol. 8, pp. 613-636, 2007.\n",
    "\n",
    "License: BSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logger = logging.getLogger(__name__)\n",
    "\n",
    "def _create_complete_graph(node_ids):\n",
    "    \"\"\"Create a complete graph from the list of node ids.\n",
    "\n",
    "    Args:\n",
    "        node_ids: a list of node ids\n",
    "\n",
    "    Returns:\n",
    "        An undirected graph (as a networkx.Graph)\n",
    "    \"\"\"\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(node_ids)\n",
    "    for (i, j) in combinations(node_ids, 2):\n",
    "        g.add_edge(i, j)\n",
    "    return g\n",
    "\n",
    "def estimate_skeleton(indep_test_func, data_matrix, alpha, **kwargs):\n",
    "    \"\"\"Estimate a skeleton graph from the statistis information.\n",
    "\n",
    "    Args:\n",
    "        indep_test_func: the function name for a conditional\n",
    "            independency test.\n",
    "        data_matrix: data (as a numpy array).\n",
    "        alpha: the significance level.\n",
    "        kwargs:\n",
    "            'max_reach': maximum value of l (see the code).  The\n",
    "                value depends on the underlying distribution.\n",
    "            'method': if 'stable' given, use stable-PC algorithm\n",
    "                (see [Colombo2014]).\n",
    "            'init_graph': initial structure of skeleton graph\n",
    "                (as a networkx.Graph). If not specified,\n",
    "                a complete graph is used.\n",
    "            'fixed_edges': Undirected edges marked here are not changed\n",
    "                (as a networkx.Graph). If not specified,\n",
    "                an empty graph is used.\n",
    "            other parameters may be passed depending on the\n",
    "                indep_test_func()s.\n",
    "    Returns:\n",
    "        g: a skeleton graph (as a networkx.Graph).\n",
    "        sep_set: a separation set (as an 2D-array of set()).\n",
    "\n",
    "    [Colombo2014] Diego Colombo and Marloes H Maathuis. Order-independent\n",
    "    constraint-based causal structure learning. In The Journal of Machine\n",
    "    Learning Research, Vol. 15, pp. 3741-3782, 2014.\n",
    "    \"\"\"\n",
    "\n",
    "    def method_stable(kwargs):\n",
    "        return ('method' in kwargs) and kwargs['method'] == \"stable\"\n",
    "\n",
    "    node_ids = range(data_matrix.shape[1])\n",
    "    node_size = data_matrix.shape[1]\n",
    "    sep_set = [[set() for i in range(node_size)] for j in range(node_size)]\n",
    "    if 'init_graph' in kwargs:\n",
    "        g = kwargs['init_graph']\n",
    "        if not isinstance(g, nx.Graph):\n",
    "            raise ValueError\n",
    "        elif not g.number_of_nodes() == len(node_ids):\n",
    "            raise ValueError('init_graph not matching data_matrix shape')\n",
    "        for (i, j) in combinations(node_ids, 2):\n",
    "            if not g.has_edge(i, j):\n",
    "                sep_set[i][j] = None\n",
    "                sep_set[j][i] = None\n",
    "    else:\n",
    "        g = _create_complete_graph(node_ids)\n",
    "\n",
    "    fixed_edges = set()\n",
    "    if 'fixed_edges' in kwargs:\n",
    "        _fixed_edges = kwargs['fixed_edges']\n",
    "        if not isinstance(_fixed_edges, nx.Graph):\n",
    "            raise ValueError\n",
    "        if not _fixed_edges.number_of_nodes() == len(node_ids):\n",
    "            raise ValueError('fixed_edges not matching data_matrix shape')\n",
    "        for (i, j) in _fixed_edges.edges:\n",
    "            fixed_edges.add((i, j))\n",
    "            fixed_edges.add((j, i))\n",
    "\n",
    "    l = 0\n",
    "    while True:\n",
    "        cont = False\n",
    "        remove_edges = []\n",
    "        for (i, j) in permutations(node_ids, 2):\n",
    "            if (i, j) in fixed_edges:\n",
    "                continue\n",
    "\n",
    "            adj_i = list(g.neighbors(i))\n",
    "            if j not in adj_i:\n",
    "                continue\n",
    "            else:\n",
    "                adj_i.remove(j)\n",
    "            if len(adj_i) >= l:\n",
    "                _logger.debug('testing %s and %s' % (i,j))\n",
    "                _logger.debug('neighbors of %s are %s' % (i, str(adj_i)))\n",
    "                if len(adj_i) < l:\n",
    "                    continue\n",
    "                for k in combinations(adj_i, l):\n",
    "                    _logger.debug('indep prob of %s and %s with subset %s'\n",
    "                                  % (i, j, str(k)))\n",
    "                    p_val = indep_test_func(data_matrix, i, j, set(k),\n",
    "                                            **kwargs)\n",
    "                    _logger.debug('p_val is %s' % str(p_val))\n",
    "                    if p_val > alpha:\n",
    "                        if g.has_edge(i, j):\n",
    "                            _logger.debug('p: remove edge (%s, %s)' % (i, j))\n",
    "                            if method_stable(kwargs):\n",
    "                                remove_edges.append((i, j))\n",
    "                            else:\n",
    "                                g.remove_edge(i, j)\n",
    "                        sep_set[i][j] |= set(k)\n",
    "                        sep_set[j][i] |= set(k)\n",
    "                        break\n",
    "                cont = True\n",
    "        l += 1\n",
    "        if method_stable(kwargs):\n",
    "            g.remove_edges_from(remove_edges)\n",
    "        if cont is False:\n",
    "            break\n",
    "        if ('max_reach' in kwargs) and (l > kwargs['max_reach']):\n",
    "            break\n",
    "\n",
    "    return (g, sep_set)\n",
    "\n",
    "def estimate_cpdag(skel_graph, sep_set):\n",
    "    \"\"\"Estimate a CPDAG from the skeleton graph and separation sets\n",
    "    returned by the estimate_skeleton() function.\n",
    "\n",
    "    Args:\n",
    "        skel_graph: A skeleton graph (an undirected networkx.Graph).\n",
    "        sep_set: An 2D-array of separation set.\n",
    "            The contents look like something like below.\n",
    "                sep_set[i][j] = set([k, l, m])\n",
    "\n",
    "    Returns:\n",
    "        An estimated DAG.\n",
    "    \"\"\"\n",
    "    dag = skel_graph.to_directed()\n",
    "    node_ids = skel_graph.nodes()\n",
    "    for (i, j) in combinations(node_ids, 2):\n",
    "        adj_i = set(dag.successors(i))\n",
    "        if j in adj_i:\n",
    "            continue\n",
    "        adj_j = set(dag.successors(j))\n",
    "        if i in adj_j:\n",
    "            continue\n",
    "        if sep_set[i][j] is None:\n",
    "            continue\n",
    "        common_k = adj_i & adj_j\n",
    "        for k in common_k:\n",
    "            if k not in sep_set[i][j]:\n",
    "                if dag.has_edge(k, i):\n",
    "                    _logger.debug('S: remove edge (%s, %s)' % (k, i))\n",
    "                    dag.remove_edge(k, i)\n",
    "                if dag.has_edge(k, j):\n",
    "                    _logger.debug('S: remove edge (%s, %s)' % (k, j))\n",
    "                    dag.remove_edge(k, j)\n",
    "\n",
    "    def _has_both_edges(dag, i, j):\n",
    "        return dag.has_edge(i, j) and dag.has_edge(j, i)\n",
    "\n",
    "    def _has_any_edge(dag, i, j):\n",
    "        return dag.has_edge(i, j) or dag.has_edge(j, i)\n",
    "\n",
    "    def _has_one_edge(dag, i, j):\n",
    "        return ((dag.has_edge(i, j) and (not dag.has_edge(j, i))) or\n",
    "                (not dag.has_edge(i, j)) and dag.has_edge(j, i))\n",
    "\n",
    "    def _has_no_edge(dag, i, j):\n",
    "        return (not dag.has_edge(i, j)) and (not dag.has_edge(j, i))\n",
    "\n",
    "    # For all the combination of nodes i and j, apply the following\n",
    "    # rules.\n",
    "    old_dag = dag.copy()\n",
    "    while True:\n",
    "        for (i, j) in permutations(node_ids, 2):\n",
    "            # Rule 1: Orient i-j into i->j whenever there is an arrow k->i\n",
    "            # such that k and j are nonadjacent.\n",
    "            #\n",
    "            # Check if i-j.\n",
    "            if _has_both_edges(dag, i, j):\n",
    "                # Look all the predecessors of i.\n",
    "                for k in dag.predecessors(i):\n",
    "                    # Skip if there is an arrow i->k.\n",
    "                    if dag.has_edge(i, k):\n",
    "                        continue\n",
    "                    # Skip if k and j are adjacent.\n",
    "                    if _has_any_edge(dag, k, j):\n",
    "                        continue\n",
    "                    # Make i-j into i->j\n",
    "                    _logger.debug('R1: remove edge (%s, %s)' % (j, i))\n",
    "                    dag.remove_edge(j, i)\n",
    "                    break\n",
    "\n",
    "            # Rule 2: Orient i-j into i->j whenever there is a chain\n",
    "            # i->k->j.\n",
    "            #\n",
    "            # Check if i-j.\n",
    "            if _has_both_edges(dag, i, j):\n",
    "                # Find nodes k where k is i->k.\n",
    "                succs_i = set()\n",
    "                for k in dag.successors(i):\n",
    "                    if not dag.has_edge(k, i):\n",
    "                        succs_i.add(k)\n",
    "                # Find nodes j where j is k->j.\n",
    "                preds_j = set()\n",
    "                for k in dag.predecessors(j):\n",
    "                    if not dag.has_edge(j, k):\n",
    "                        preds_j.add(k)\n",
    "                # Check if there is any node k where i->k->j.\n",
    "                if len(succs_i & preds_j) > 0:\n",
    "                    # Make i-j into i->j\n",
    "                    _logger.debug('R2: remove edge (%s, %s)' % (j, i))\n",
    "                    dag.remove_edge(j, i)\n",
    "\n",
    "            # Rule 3: Orient i-j into i->j whenever there are two chains\n",
    "            # i-k->j and i-l->j such that k and l are nonadjacent.\n",
    "            #\n",
    "            # Check if i-j.\n",
    "            if _has_both_edges(dag, i, j):\n",
    "                # Find nodes k where i-k.\n",
    "                adj_i = set()\n",
    "                for k in dag.successors(i):\n",
    "                    if dag.has_edge(k, i):\n",
    "                        adj_i.add(k)\n",
    "                # For all the pairs of nodes in adj_i,\n",
    "                for (k, l) in combinations(adj_i, 2):\n",
    "                    # Skip if k and l are adjacent.\n",
    "                    if _has_any_edge(dag, k, l):\n",
    "                        continue\n",
    "                    # Skip if not k->j.\n",
    "                    if dag.has_edge(j, k) or (not dag.has_edge(k, j)):\n",
    "                        continue\n",
    "                    # Skip if not l->j.\n",
    "                    if dag.has_edge(j, l) or (not dag.has_edge(l, j)):\n",
    "                        continue\n",
    "                    # Make i-j into i->j.\n",
    "                    _logger.debug('R3: remove edge (%s, %s)' % (j, i))\n",
    "                    dag.remove_edge(j, i)\n",
    "                    break\n",
    "\n",
    "            # Rule 4: Orient i-j into i->j whenever there are two chains\n",
    "            # i-k->l and k->l->j such that k and j are nonadjacent.\n",
    "            #\n",
    "            # However, this rule is not necessary when the PC-algorithm\n",
    "            # is used to estimate a DAG.\n",
    "\n",
    "        if nx.is_isomorphic(dag, old_dag):\n",
    "            break\n",
    "        old_dag = dag.copy()\n",
    "\n",
    "    return dag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a custom Pearson correlation test for two columns (i and j) in a data matrix\n",
    "with respect to a set of selected columns (S).\n",
    "\n",
    "Parameters:\n",
    "- data_matrix (numpy.ndarray): The data matrix containing the dataset.\n",
    "- i (int): Index of the first column for Pearson correlation.\n",
    "- j (int): Index of the second column for Pearson correlation.\n",
    "- S (list or array-like): A list of indices representing columns to consider for correlation.\n",
    "\n",
    "Returns:\n",
    "- bool: True if the p-value of the Pearson correlation test is greater than 0.01,\n",
    "        indicating that the columns are independent at the 0.01 significance level.\n",
    "        False otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pearsonr(data_matrix, i, j, S):\n",
    "    # Extract columns from the data matrix based on indices i, j, and S\n",
    "    xi = data_matrix[:, i]\n",
    "    xj = data_matrix[:, j]\n",
    "    xs = data_matrix[:, list(S)]\n",
    "\n",
    "    # Perform Pearson correlation test\n",
    "    correlation_coefficient, p_value = pearsonr(xi, xj)\n",
    "\n",
    "    # Return True if p-value is greater than the significance level (independence holds)\n",
    "    return p_value > 0.01  # Adjust the significance level as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 31)\n",
      "<U11\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.genfromtxt(\"C:/Users/max/Desktop/Home/DAG/publications/OSD-366/chromosomes/chromosome_1.csv\", delimiter=\",\", dtype = None, encoding = None)\n",
    "names = data[0].tolist()\n",
    "data = data[1:]\n",
    "data = data.tolist()\n",
    "data = np.delete(data, 0, 1)\n",
    "data = np.delete(data, 27, 1)\n",
    "data = np.delete(data, 27, 1)\n",
    "# print(data[:5])\n",
    "# print(\"\\n\\n\\n\")\n",
    "# print(names)\n",
    "\n",
    "random_row_indices = np.random.choice(data.shape[0], size=100, replace=False)\n",
    "data = data[random_row_indices]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "print(data.dtype)\n",
    "data = data.astype('float64')\n",
    "print(data.dtype)\n",
    "\n",
    "(graph, sep_set) = estimate_skeleton(indep_test_func=custom_pearsonr,\n",
    "                                        data_matrix=data,\n",
    "                                        alpha=0.01)\n",
    "graph = estimate_cpdag(skel_graph=graph, sep_set=sep_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
